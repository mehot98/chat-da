# CI/CD

# EC2

### ì ‘ì†í•˜ê¸°

EC2ì— sshë¥¼ ì‚¬ìš©í•˜ì—¬ ì ‘ì†í•œë‹¤.

- pem íŒŒì¼ì„ ì €ì¥
- ì €ì¥í•œ ê²½ë¡œì—ì„œ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰ (ì²˜ìŒ ì ‘ì† ì‹œ known host ì¶”ê°€)

```powershell
ssh -i J10S004T.pem ubuntu@j10s004.p.ssafy.io
```

# Docker

> [https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository](https://docs.docker.com/engine/install/ubuntu/#install-using-the-repository)

## Docker Engine ì„¤ì¹˜

1. ë„ì»¤ `apt` ë ˆí¬ì§€í† ë¦¬ ì„¤ì •

```bash
# Add Docker's official GPG key:
sudo apt-get update
sudo apt-get install ca-certificates curl
sudo install -m 0755 -d /etc/apt/keyrings
sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
sudo chmod a+r /etc/apt/keyrings/docker.asc

# Add the repository to Apt sources:
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
```

1. ë„ì»¤ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
```

2. ë„ì»¤ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸

```bash
docker -v
# Docker version 25.0.4, build 1a576c5
docker compose -v
# Docker Compose version v2.24.7
```

3. ë„ì»¤ ê¶Œí•œ ê·¸ë£¹ ì„¤ì •: sudo ì—†ì´ docker ëª…ë ¹ì–´ ì‚¬ìš© ê°€ëŠ¥

```bash
sudo groupadd docker
sudo usermod -aG docker $USER
```

## EC2 ê¸°ë³¸ ì„¤ì •

1. `chatda-setup` ë ˆí¬ì§€í† ë¦¬ í´ë¡ 

```bash
git clone https://lab.ssafy.com/0onionion0/chatda-setup
cd chatda-setup
```

2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ì§ì ‘ ì„¤ì • ë˜ëŠ” íŒŒì¼ ì¶”ê°€)

- `.env`

  ```bash
  # Jenkins container
  OPENAI_API_KEY=${YOUR_OPEN_API_KEY}
  MYSQL_USER=chatda
  MYSQL_PASSWORD=${YOUR_MYSQL_PASSWORD}
  MYSQL_HOST=chatda-mysql
  MYSQL_PORT=3306
  MYSQL_DATABASE=chatda
  # MySQL container
  MYSQL_ROOT_PASSWORD=${YOUR_MYSQL_ROOT_PASSWORD}
  MYSQL_DATABASE=chatda
  MYSQL_USER=chatda
  MYSQL_PASSWORD=${YOUR_MYSQL_PASSWORD}
  ```

3. Secret ì¶”ê°€

- `./server/keys/google-cloud-key.json`
  ê²½ë¡œì— íŒŒì¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ ì¶”ê°€

4. Docker Compose ì‹¤í–‰

```bash
docker compose up -d
```

# Nginx

- `80`, `443` í¬íŠ¸ë¥¼ listení•œë‹¤.
- `/api` : ê¸°ë³¸ API ì„œë²„
- `/jenkins` : ì  í‚¨ìŠ¤ ì„œë²„

## HTTPS ì„¤ì •

Docker Compose ì‹¤í–‰ ì™„ë£Œ í›„ ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰

```bash
docker compose exec nginx certbot --nginx --agree-tos
```

ì´ë©”ì¼, ë„ë©”ì¸ì„ ì…ë ¥í•˜ë©´ ì™„ë£Œëœë‹¤.

# Jenkins

> [https://j10s004.p.ssafy.io/jenkins](https://j10s004.p.ssafy.io/jenkins)

## Jenkins ì„¤ì •

### ì²˜ìŒ ì ‘ì† ì‹œ

- **Unlock Jenkins**: ì•„ë˜ ëª…ë ¹ì–´ ì‹¤í–‰ í›„ ì¶œë ¥ ë¶™ì—¬ë„£ê¸°

```bash
docker compose exec jenkins cat /var/jenkins_home/secrets/initialAdminPassword
```

- **Create First Admin User**: ê´€ë¦¬ì ê³„ì • ìƒì„±, ì•Œì•„ì„œ í•˜ì.
- **Jenkins URL**: `[https://j10s004.p.ssafy.io/jenkins](http://j10s004.p.ssafy.io/jenkins)` (ìë™ ì„¤ì •)

### í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜

- **System Configuration - Plugins - Available plugins**ì—ì„œ ì•„ë˜ í”ŒëŸ¬ê·¸ì¸ ì²´í¬
  - GitLab Plugin
  - Pipeline: Stage View
- **+ Install** í´ë¦­í•´ì„œ ì„¤ì¹˜

### Credentials ì¶”ê°€

- **Security - Credentials - System - Global credentials** ì ‘ì† (í•„ìš” ì‹œ Store, Domain ë³€ê²½ ê°€ëŠ¥)
- **+ Add Credentials** í´ë¦­ í›„ GitLab ë¡œê·¸ì¸ ì •ë³´ ì…ë ¥
  - **Kind**: `Username with password`
  - **Scope**: `Global (Jenkins, nodes, items, all child items, etc)`
  - **Username**: GitLab ì•„ì´ë””
  - **Password**: GitLab ë¹„ë°€ë²ˆí˜¸
  - **ID**: `gitlab-personal-login`
- **Create** í´ë¦­

### GitLab ì—°ê²° ì„¤ì •

- **System Configuration - System**ì—ì„œ ì•„ë˜ í•­ëª© ì„¤ì •
- **GitLab**
  - Connection name: ê¹ƒë© ì—°ê²° ì´ë¦„ (ììœ )
  - GitLab host URL: `https://lab.ssafy.com`
  - Credentials: ìœ„ ê³¼ì •ì—ì„œ ì¶”ê°€í•œ GitLab Username with password ì„ íƒ

## Pipeline ì¶”ê°€ ë° ê´€ë¦¬

### **Pipeline ìƒì„±**

- ë©”ì¸ í˜ì´ì§€ì—ì„œ ì¢Œì¸¡ì˜ **ìƒˆë¡œìš´ Item** í´ë¦­
- ì‘ì—… ì´ë¦„ ì…ë ¥
- ì•„ë˜ ëª©ë¡ì—ì„œ **Pipeline** ì„ íƒ
- **OK** í´ë¦­ (ìƒì„±ë˜ê³  ì„¤ì • í˜ì´ì§€ë¡œ ì´ë™ë¨)

### Pipeline ì„¤ì •

Item í˜ì´ì§€ì—ì„œ ì¢Œì¸¡ì˜ **êµ¬ì„±**ìœ¼ë¡œ ì ‘ì†

- **General - Build Triggers**ì—ì„œ ì•„ë˜ í•­ëª© ì²´í¬
  - **Build when a change is pushed to GitLab. GitLab webhook URL: â€¦**
  - í•˜ìœ„ í•­ëª© ì¤‘ **Push Events**ë§Œ ì²´í¬, ë‚˜ë¨¸ì§€ëŠ” ì²´í¬ í•´ì œ
  - **ê³ ê¸‰ - Secret Token:** Generate í›„ ì €ì¥í•´ë‘ê¸°
  - GitLab webhook URL ì €ì¥í•´ë‘ê¸°
- **Pipeline** ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (TODO: Jenkinsfileë¡œ ìµœëŒ€í•œ ë¶„ë¦¬)
- (ìš°ë¦¬ê°€ ì‚¬ìš©í•˜ëŠ” Pipeline ëª©ë¡)

  ```groovy
  pipeline {
      agent any

      stages {
          stage('Clone') {
              steps {
                  echo 'Clone'
                  git branch: 'develop',
                      url: 'https://lab.ssafy.com/s10-s-project/S10P21S004.git',
                      credentialsId: 'gitlab-personal-token'
              }
          }

          stage('Copy key') {
              // when {
                  // changeset 'server/**'
              // }
              steps {
                  sh 'echo server changed'
                  sh 'cp /var/server/compose.yaml ./server/compose.yaml'
                  sh 'cp /var/server/keys/google-cloud-key.json ./server/chatdaAPI/secret/google-cloud-key.json'
              }
          }

          stage('Run Docker') {
              // when {
                  // changeset 'server/**'
              // }
              steps {
                  dir('server') {
                      sh 'echo server changed'
                      sh 'docker compose up -d'
                  }
              }
          }
      }
  }
  ```

### GitLab ì—°ê²° ì„¤ì • (GitLab)

- GitLab ë ˆí¬ì§€í† ë¦¬ì—ì„œ **Settings - Webhooks - Project Hooks**ì—ì„œ **Add new webhook** í´ë¦­
- ì•„ë˜ í•­ëª© ì²´í¬
  - **URL**: ìœ„ì—ì„œ ì €ì¥í•œ GitLab webhook URL ì…ë ¥
  - **Secret token**: ìœ„ì—ì„œ ì €ì¥í•œ Secret Token ì…ë ¥
  - **Trigger**ì—ì„œ **Push events**ë§Œ ì²´í¬, **Wildcard pattern**ìœ¼ë¡œ `develop` ì…ë ¥ (ë°°í¬í•  ë¸Œëœì¹˜)
- **Add webhook** í´ë¦­

<aside>
ğŸ’¡ ìœ„ Pipeline ì„¤ì •ì€ develop ë¸Œëœì¹˜ ì—…ë°ì´íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë°°í¬ë˜ë¯€ë¡œ í”„ë¡œë•ì…˜ ë°°í¬ ì‹œ ìˆ˜ì •í•˜ê¸°
</aside>

# ELK

`docker-compose.yaml`

```bash
version: '3.7'

services:

  # The 'setup' service runs a one-off script which initializes users inside
  # Elasticsearch â€” such as 'logstash_internal' and 'kibana_system' â€” with the
  # values of the passwords defined in the '.env' file. It also creates the
  # roles required by some of these users.
  #
  # This task only needs to be performed once, during the *initial* startup of
  # the stack. Any subsequent run will reset the passwords of existing users to
  # the values defined inside the '.env' file, and the built-in roles to their
  # default permissions.
  #
  # By default, it is excluded from the services started by 'docker compose up'
  # due to the non-default profile it belongs to. To run it, either provide the
  # '--profile=setup' CLI flag to Compose commands, or "up" the service by name
  # such as 'docker compose up setup'.
  setup:
    profiles:
      - setup
    build:
      context: setup/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    init: true
    volumes:
      - ./setup/entrypoint.sh:/entrypoint.sh:ro,Z
      - ./setup/lib.sh:/lib.sh:ro,Z
      - ./setup/roles:/roles:ro,Z
    environment:
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
      METRICBEAT_INTERNAL_PASSWORD: ${METRICBEAT_INTERNAL_PASSWORD:-}
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      HEARTBEAT_INTERNAL_PASSWORD: ${HEARTBEAT_INTERNAL_PASSWORD:-}
      MONITORING_INTERNAL_PASSWORD: ${MONITORING_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch

  elasticsearch:
    build:
      context: elasticsearch/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - elasticsearch:/usr/share/elasticsearch/data:Z
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      node.name: elasticsearch
      ES_JAVA_OPTS: -Xms512m -Xmx512m
      # Bootstrap password.
      # Used to initialize the keystore during the initial startup of
      # Elasticsearch. Ignored on subsequent runs.
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
      # Use single node discovery in order to disable production mode and avoid bootstrap checks.
      # see: https://www.elastic.co/guide/en/elasticsearch/reference/current/bootstrap-checks.html
      discovery.type: single-node
    networks:
      - elk
    restart: unless-stopped

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:ro,Z
    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xms256m -Xmx256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
    ports:
      - 5601:5601
    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
    restart: unless-stopped

  filebeat:
    build:
      context: extensions/filebeat/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    # Run as 'root' instead of 'filebeat' (uid 1000) to allow reading
    # 'docker.sock' and the host's filesystem.
    user: root
    command:
      # Log to stderr.
      - -e
      # Disable config file permissions checks. Allows mounting
      # 'config/filebeat.yml' even if it's not owned by root.
      # see: https://www.elastic.co/guide/en/beats/libbeat/current/config-file-permissions.html
      - --strict.perms=false
    volumes:
      - ./extensions/filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro,Z
      - type: bind
        source: /var/lib/docker/containers
        target: /var/lib/docker/containers
        read_only: true
      - type: bind
        source: /var/run/docker.sock
        target: /var/run/docker.sock
        read_only: true
    environment:
      FILEBEAT_INTERNAL_PASSWORD: ${FILEBEAT_INTERNAL_PASSWORD:-}
      BEATS_SYSTEM_PASSWORD: ${BEATS_SYSTEM_PASSWORD:-}
    networks:
      - elk
    depends_on:
      - elasticsearch
      - logstash
      - kibana

networks:
  elk:
    driver: bridge

volumes:
  elasticsearch:

```

`elasticsearch/Dockerfile`

```yaml
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION}

# Add your elasticsearch plugins setup here
# Example: RUN elasticsearch-plugin install analysis-icu

```

`elasticsearch/config/elasticsearch.yaml`

```yaml
---
## Default Elasticsearch configuration from Elasticsearch base image.
## https://github.com/elastic/elasticsearch/blob/main/distribution/docker/src/docker/config/elasticsearch.yml
#
cluster.name: docker-cluster
network.host: 0.0.0.0

## X-Pack settings
## see https://www.elastic.co/guide/en/elasticsearch/reference/current/security-settings.html
#
xpack.license.self_generated.type: trial
xpack.security.enabled: true
```

`logstash/Dockerfile`

```yaml
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/logstash/logstash:${ELASTIC_VERSION}

# Add your logstash plugins setup here
# Example: RUN logstash-plugin install logstash-filter-json

```

`logstash/config/logstash.yaml`

```yaml
---
## Default Logstash configuration from Logstash base image.
## https://github.com/elastic/logstash/blob/main/docker/data/logstash/config/logstash-full.yml
#
http.host: 0.0.0.0

node.name: logstash
```

`logstash/pipeline/logstash.conf`

```yaml
input {
	beats {
		port => 5044
	}

	tcp {
		port => 50000
	}
}

## Add your filters / logstash plugins configuration here

output {
	elasticsearch {
		hosts =>  "elasticsearch:9200"
		user => "logstash_internal"
		password => "${LOGSTASH_INTERNAL_PASSWORD}"
	}
}

```

`kibana/Dockerfile`

```yaml
ARG ELASTIC_VERSION

# https://www.docker.elastic.co/
FROM docker.elastic.co/kibana/kibana:${ELASTIC_VERSION}

# Add your kibana plugins setup here
# Example: RUN kibana-plugin install <name|url>

```

`kibana/config/kibana.yaml`

```yaml
---
## Default Kibana configuration from Kibana base image.
## https://github.com/elastic/kibana/blob/main/src/dev/build/tasks/os_packages/docker_generator/templates/kibana_yml.template.ts
#
server.name: kibana
server.host: 0.0.0.0
elasticsearch.hosts: [http://elasticsearch:9200]

monitoring.ui.container.elasticsearch.enabled: true
monitoring.ui.container.logstash.enabled: true

## X-Pack security credentials
#
elasticsearch.username: kibana_system
elasticsearch.password: ${KIBANA_SYSTEM_PASSWORD}

## Encryption keys (optional but highly recommended)
##
## Generate with either
##  $ docker container run --rm docker.elastic.co/kibana/kibana:8.6.2 bin/kibana-encryption-keys generate
##  $ openssl rand -hex 32
##
## https://www.elastic.co/guide/en/kibana/current/using-kibana-with-security.html
## https://www.elastic.co/guide/en/kibana/current/kibana-encryption-keys.html
#
#xpack.security.encryptionKey:
#xpack.encryptedSavedObjects.encryptionKey:
#xpack.reporting.encryptionKey:

## Fleet
## https://www.elastic.co/guide/en/kibana/current/fleet-settings-kb.html
#
xpack.fleet.agents.fleet_server.hosts: [http://fleet-server:8220]

xpack.fleet.outputs:
  - id: fleet-default-output
    name: default
    type: elasticsearch
    hosts: [http://elasticsearch:9200]
    is_default: true
    is_default_monitoring: true

xpack.fleet.packages:
  - name: fleet_server
    version: latest
  - name: system
    version: latest
  - name: elastic_agent
    version: latest
  - name: docker
    version: latest
  - name: apm
    version: latest

xpack.fleet.agentPolicies:
  - name: Fleet Server Policy
    id: fleet-server-policy
    description: Static agent policy for Fleet Server
    monitoring_enabled:
      - logs
      - metrics
    package_policies:
      - name: fleet_server-1
        package:
          name: fleet_server
      - name: system-1
        package:
          name: system
      - name: elastic_agent-1
        package:
          name: elastic_agent
      - name: docker-1
        package:
          name: docker
  - name: Agent Policy APM Server
    id: agent-policy-apm-server
    description: Static agent policy for the APM Server integration
    monitoring_enabled:
      - logs
      - metrics
    package_policies:
      - name: system-1
        package:
          name: system
      - name: elastic_agent-1
        package:
          name: elastic_agent
      - name: apm-1
        package:
          name: apm
        # See the APM package manifest for a list of possible inputs.
        # https://github.com/elastic/apm-server/blob/v8.5.0/apmpackage/apm/manifest.yml#L41-L168
        inputs:
          - type: apm
            vars:
              - name: host
                value: 0.0.0.0:8200
              - name: url
                value: http://apm-server:8200
```

`extensions/filebeat/Dockerfile`

```yaml
ARG ELASTIC_VERSION

FROM docker.elastic.co/beats/filebeat:${ELASTIC_VERSION}
```

`extensions/filebeat/config/filebeat.yaml`

```yaml
## Filebeat configuration
## https://github.com/elastic/beats/blob/main/deploy/docker/filebeat.docker.yml
#

name: filebeat

filebeat.config:
  modules:
    path: ${path.config}/modules.d/*.yml
    reload.enabled: false

filebeat.autodiscover:
  providers:
    # The Docker autodiscover provider automatically retrieves logs from Docker
    # containers as they start and stop.
    - type: docker
      hints.enabled: true
      hints.default_config:
        type: container
        paths:
          - /var/lib/docker/containers/${data.container.id}/*-json.log
      templates:
        - condition:
            contains:
              docker.container.image: elasticsearch
          config:
            - module: elasticsearch
              server:
                input:
                  type: container
                  paths:
                    - /var/lib/docker/containers/${data.container.id}/*-json.log

processors:
  - decode_json_fields:
      fields: ["message"]
      process_array: false
      max_depth: 2
      target: ""
      overwrite_keys: true
      add_error_key: false

monitoring:
  enabled: false
  #enabled: true
  #logstash:
  #  username: beats_system
  #  password: ${BEATS_SYSTEM_PASSWORD}

#output.elasticsearch:
#  hosts: [ http://elasticsearch:9200 ]
#  username: filebeat_internal
#  password: ${FILEBEAT_INTERNAL_PASSWORD}

output.logstash:
  enabled: true
  hosts: ["logstash:5044"]
  username: logstash_internal
  password: ${LOGSTASH_INTERNAL_PASSWORD}
## HTTP endpoint for health checking
## https://www.elastic.co/guide/en/beats/filebeat/current/http-endpoint.html
#

http:
  enabled: true
  host: 0.0.0.0
```
